{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff1d95d",
   "metadata": {},
   "source": [
    "# Photomath assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73135307",
   "metadata": {},
   "source": [
    "The assignment was to provide an implementation that can read \"very very pretty\" handwritten math expressions and calculate the result.\n",
    "I haven't been able to achieve the best results, as my final implementation still has trouble with some symbols (brackets and minus symbol). However, considering this was my first time using OpenCV and one of the first encounters with CNNs, it was a fun learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5fb2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ea3a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 16\n",
    "MAX_EPOCHS = 10\n",
    "PICKLE_FILE = 'dataset/dataset_large.pickle'\n",
    "MAP_SYMBOLS = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4,\n",
    "               '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n",
    "               '+': 10, '-': 11, \n",
    "              'times': 12, 'div': 13, '(': 14, ')': 15}\n",
    "VEC_SYMBOLS = np.vectorize(MAP_SYMBOLS.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457876ba",
   "metadata": {},
   "source": [
    "First part of the assignment was to detect each character and find its bounding box. This was done with OpenCV in the python file <code>detector.py</code>\n",
    "In order to classify the cropped characters, we need to train a CNN, and for that we need a dataset.\n",
    "After trying out many datasets that I could find online, I've settled on the following Kaggle dataset (https://www.kaggle.com/xainano/handwrittenmathsymbols). \n",
    "I've had some trouble detecting '/' as the division operator (it would often get mixed up with the digit 1), so I've decided to use 'รท' for the divison operator. Since there was a disbalance in the number of examples for some symbols, I've selected approx. 4000 images for each symbol and preprocessed the images to 'MNIST format'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe580b",
   "metadata": {},
   "source": [
    "## Loading the data, splitting into training and testing sets and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08dfff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PICKLE_FILE, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X = np.array(data['img'])\n",
    "y = VEC_SYMBOLS(np.array(data['label']))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train = X_train.astype(np.float32)/255\n",
    "X_test = X_test.astype(np.float32)/255\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c6c15",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e775df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape =(28, 28, 1), activation ='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation ='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation ='relu'))\n",
    "model.add(Dense(50, activation ='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation ='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss ='categorical_crossentropy', \n",
    "              optimizer ='adam', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2886948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "53a7f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=4, verbose=1, min_delta=0.01)\n",
    "mc = ModelCheckpoint('bestmodel.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c2f1f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.9137 - accuracy: 0.7212\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.90097, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 40s 187ms/step - loss: 0.9138 - accuracy: 0.7212 - val_loss: 0.3518 - val_accuracy: 0.9010\n",
      "Epoch 2/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8958\n",
      "Epoch 00002: val_accuracy improved from 0.90097 to 0.93199, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 37s 184ms/step - loss: 0.3425 - accuracy: 0.8958 - val_loss: 0.2348 - val_accuracy: 0.9320\n",
      "Epoch 3/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9304\n",
      "Epoch 00003: val_accuracy improved from 0.93199 to 0.95525, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 34s 168ms/step - loss: 0.2356 - accuracy: 0.9304 - val_loss: 0.1659 - val_accuracy: 0.9553\n",
      "Epoch 4/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9468\n",
      "Epoch 00004: val_accuracy did not improve from 0.95525\n",
      "204/204 [==============================] - 45s 220ms/step - loss: 0.1794 - accuracy: 0.9468 - val_loss: 0.1494 - val_accuracy: 0.9537\n",
      "Epoch 5/10\n",
      "204/204 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9557\n",
      "Epoch 00005: val_accuracy improved from 0.95525 to 0.96544, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 80s 393ms/step - loss: 0.1486 - accuracy: 0.9557 - val_loss: 0.1236 - val_accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9622\n",
      "Epoch 00006: val_accuracy improved from 0.96544 to 0.96655, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 67s 327ms/step - loss: 0.1265 - accuracy: 0.9622 - val_loss: 0.1097 - val_accuracy: 0.9665\n",
      "Epoch 7/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9672\n",
      "Epoch 00007: val_accuracy improved from 0.96655 to 0.97253, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 61s 298ms/step - loss: 0.1105 - accuracy: 0.9672 - val_loss: 0.0929 - val_accuracy: 0.9725\n",
      "Epoch 8/10\n",
      "204/204 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9690\n",
      "Epoch 00008: val_accuracy did not improve from 0.97253\n",
      "204/204 [==============================] - 57s 278ms/step - loss: 0.1033 - accuracy: 0.9690 - val_loss: 0.0981 - val_accuracy: 0.9690\n",
      "Epoch 9/10\n",
      "204/204 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9731\n",
      "Epoch 00009: val_accuracy improved from 0.97253 to 0.97918, saving model to bestmodel_operators.h5\n",
      "204/204 [==============================] - 56s 277ms/step - loss: 0.0900 - accuracy: 0.9731 - val_loss: 0.0792 - val_accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "203/204 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9747\n",
      "Epoch 00010: val_accuracy did not improve from 0.97918\n",
      "204/204 [==============================] - 56s 275ms/step - loss: 0.0837 - accuracy: 0.9747 - val_loss: 0.0741 - val_accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=MAX_EPOCHS, callbacks=cb, batch_size=200, shuffle=True, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "524bb774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 14ms/step - loss: 0.0413 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04131867364048958, 0.992516815662384]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_operators_test, y_operators_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcc32700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bestmodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
