{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff1d95d",
   "metadata": {},
   "source": [
    "# Photomath assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73135307",
   "metadata": {},
   "source": [
    "The assignment was to provide an implementation that can read \"very very pretty\" handwritten math expressions and calculate the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5fb2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ea3a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 16\n",
    "MAX_EPOCHS = 10\n",
    "PICKLE_FILE = 'dataset/dataset.pickle'\n",
    "MAP_SYMBOLS = {'+': 10, '-': 11, \n",
    "              'times': 12, 'div': 13, \n",
    "              '(': 14, ')': 15}\n",
    "VEC_SYMBOLS = np.vectorize(MAP_SYMBOLS.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457876ba",
   "metadata": {},
   "source": [
    "First part of the assignment is to detect each character and find its bounding box. This is done with OpenCV in the python file <code>detector.py</code>\n",
    "In order to classify the cropped characters, we need to train a CNN, and for that we need a dataset.\n",
    "Since I couldn't find an appropriate dataset containing both digits and operators, I combined the well-known MNIST dataset with a dataset I found on Kaggle containing the required operators ('https://www.kaggle.com/xainano/handwrittenmathsymbols'). I've had some trouble detecting '/' as the division operator (it would often get mixed up with the digit 1), so I've decided to use 'รท' for the divison operator. The images of operators needed to be resized and converted to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "This part "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe580b",
   "metadata": {},
   "source": [
    "## Loading the data, splitting into training and testing sets and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc04dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "with open(PICKLE_FILE, 'rb') as f:\n",
    "    operators = pickle.load(f)\n",
    "\n",
    "X_operators = np.array(operators['img'])\n",
    "y_operators = VEC_SYMBOLS(np.array(operators['label']))\n",
    "X_operators_train, X_operators_test, y_operators_train, y_operators_test = train_test_split(X_operators, y_operators, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3002a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_train, X_operators_train, axis=0)\n",
    "y_train = np.append(y_train, y_operators_train, axis=0)\n",
    "X_test = np.append(X_test, X_operators_test, axis=0)\n",
    "y_test = np.append(y_test, y_operators_test, axis=0)\n",
    "X_train = X_train.astype(np.float32)/255\n",
    "X_test = X_test.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4066c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7cae22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c6c15",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fc7f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2886948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c2f1f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2302/2302 [==============================] - 120s 52ms/step - loss: 0.1286 - accuracy: 0.9616 - val_loss: 0.0424 - val_accuracy: 0.9910\n",
      "Epoch 2/10\n",
      "2302/2302 [==============================] - 113s 49ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.0163 - val_accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "2302/2302 [==============================] - 111s 48ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0128 - val_accuracy: 0.9969\n",
      "Epoch 4/10\n",
      "2302/2302 [==============================] - 110s 48ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0171 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "2302/2302 [==============================] - 108s 47ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0129 - val_accuracy: 0.9980\n",
      "Epoch 6/10\n",
      "2302/2302 [==============================] - 108s 47ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0116 - val_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "2302/2302 [==============================] - 109s 48ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "2302/2302 [==============================] - 102s 44ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0140 - val_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "2302/2302 [==============================] - 107s 46ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "2302/2302 [==============================] - 104s 45ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0160 - val_accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=MAX_EPOCHS, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "524bb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 7s 15ms/step - loss: 0.0321 - accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03206757828593254, 0.9936590194702148]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fcc32700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bestmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9125ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
